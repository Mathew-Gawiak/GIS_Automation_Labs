{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.plot import show\n",
    "from matplotlib import pyplot\n",
    "from math import pi    \n",
    "from scipy import ndimage\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coeficient of recovery across all years was 0.021795632717297512\n",
      "For 2002 the recovery ratio was 0.41127\n",
      "For 2003 the recovery ratio was 0.54127\n",
      "For 2004 the recovery ratio was 0.51346\n",
      "For 2005 the recovery ratio was 0.61525\n",
      "For 2006 the recovery ratio was 0.71617\n",
      "For 2007 the recovery ratio was 0.70541\n",
      "For 2008 the recovery ratio was 0.73951\n",
      "For 2009 the recovery ratio was 0.71263\n",
      "For 2010 the recovery ratio was 0.5851\n",
      "For 2011 the recovery ratio was 0.62589\n"
     ]
    }
   ],
   "source": [
    "# Slope and Aspect Calculation Function\n",
    "def slopeAspect(dem, cs):\n",
    "    \"\"\"Calculates slope and aspect using the 3rd-order finite difference method\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dem : numpy array\n",
    "        A numpy array of a DEM\n",
    "    cs : float\n",
    "        The cell size of the original DEM\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy arrays\n",
    "        Slope and Aspect arrays\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    dzdx = ndimage.convolve(dem, kernel, mode='mirror') / (8 * cs)\n",
    "    dzdy = ndimage.convolve(dem, kernel.T, mode='mirror') / (8 * cs)\n",
    "    slp = np.arctan((dzdx ** 2 + dzdy ** 2) ** 0.5) * 180 / pi\n",
    "    ang = np.arctan2(-dzdy, dzdx) * 180 / pi\n",
    "    aspect = np.where(ang > 90, 450 - ang, 90 - ang)\n",
    "    return slp, aspect\n",
    "\n",
    "# Reclassify Aspect Function\n",
    "def reclassAspect(npArray):\n",
    "    \"\"\"Reclassify aspect array to 8 cardinal directions (N,NE,E,SE,S,SW,W,NW),\n",
    "    encoded 1 to 8, respectively (same as ArcGIS aspect classes).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    npArray : numpy array\n",
    "        numpy array with aspect values 0 to 360\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        numpy array with cardinal directions\n",
    "    \"\"\"\n",
    "    return np.where((npArray > 22.5) & (npArray <= 67.5), 2,\n",
    "    np.where((npArray > 67.5) & (npArray <= 112.5), 3,\n",
    "    np.where((npArray > 112.5) & (npArray <= 157.5), 4,\n",
    "    np.where((npArray > 157.5) & (npArray <= 202.5), 5,\n",
    "    np.where((npArray > 202.5) & (npArray <= 247.5), 6,\n",
    "    np.where((npArray > 247.5) & (npArray <= 292.5), 7,\n",
    "    np.where((npArray > 292.5) & (npArray <= 337.5), 8, 1)))))))\n",
    "\n",
    "# Reclassify np array function\n",
    "def reclassByHisto(npArray, bins):\n",
    "    \"\"\"Reclassify np array based on a histogram approach using a specified\n",
    "    number of bins. Returns the reclassified numpy array and the classes from\n",
    "    the histogram.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    npArray : numpy array\n",
    "        Array to be reclassified\n",
    "    bins : int\n",
    "        Number of bins\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        umpy array with reclassified values\n",
    "    \"\"\"\n",
    "    histo = np.histogram(npArray, bins)[1]\n",
    "    rClss = np.zeros_like(npArray)\n",
    "    for i in range(bins):\n",
    "        rClss = np.where((npArray >= histo[i]) & (npArray <= histo[i + 1]),\n",
    "                         i + 1, rClss)\n",
    "    return rClss\n",
    "\n",
    "# Open Files\n",
    "big_Elk_dem = rasterio.open(r'./data/data/bigElk_dem.tif')\n",
    "fire_perimeter = rasterio.open(r'./data/data/fire_perimeter.tif')\n",
    "forest_files = glob.glob(r'./data/data/L5_big_elk/*tif')\n",
    "\n",
    "# Arrays\n",
    "dem_array = big_Elk_dem.read(1)\n",
    "fire_perimeter_array = fire_perimeter.read(1)\n",
    "\n",
    "# Apply Functions\n",
    "slope, aspect = slopeAspect(dem_array, 30)\n",
    "aspect_reclass = reclassAspect(aspect)\n",
    "slope_reclass = reclassByHisto(slope, 10)\n",
    "\n",
    "# Red and Infrared Bands\n",
    "red = glob.glob(r'./data/data/L5_big_elk/*B3.tif')\n",
    "nir = glob.glob(r'./data/data/L5_big_elk/*B4.tif')\n",
    "healthy = np.where(fire_perimeter_array == 2)\n",
    "burned = np.where(fire_perimeter_array ==1)\n",
    "\n",
    "# Lists\n",
    "means = []\n",
    "rr = []\n",
    "years = ['2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011']\n",
    "\n",
    "#Part I: read and zip band3 and band4, calculate NDVI, RR, line, mean coefficient, print\n",
    "for x,y in zip(red, nir):\n",
    "    red = rasterio.open(x,'r').read(1)\n",
    "    nir = rasterio.open(y,'r').read(1)\n",
    "    ndvi = ((nir-red)/(nir+red))\n",
    "    ndvi_mean = ndvi[healthy].mean()\n",
    "    recovery_ratio = ndvi/ndvi_mean\n",
    "    burn_mean = recovery_ratio[burned].mean()\n",
    "    means.append(burn_mean)\n",
    "    flat = recovery_ratio.ravel()\n",
    "    rr.append(flat)\n",
    "stacked_rr = np.vstack(rr)\n",
    "line = np.polyfit(range(10), stacked_rr, 1)[0]\n",
    "line_reshape = line.reshape(280, 459)\n",
    "mean_coeficient = np.where(fire_perimeter_array==1, line_reshape, np.nan)\n",
    "print('The coeficient of recovery across all years was', np.nanmean(mean_coeficient))\n",
    "for y,z in zip(years, means):\n",
    "    print('For', y, 'the recovery ratio was', round(np.nanmean(z),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-61b2015e64e2>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-61b2015e64e2>\"\u001b[1;36m, line \u001b[1;32m37\u001b[0m\n\u001b[1;33m    print('As the slope increases the number of burned pixels increases. The aspect did not seem to be as much of a factor, however there is more of a burned area in the East.'\u001b[0m\n\u001b[1;37m                                                                                                                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Part II: Function for stats and csv output, slope and aspect csv files, creat GTiff\n",
    "def zonal_satistics_as_table(zone_raster, value_raster, output_csv):\n",
    "    mean_stats = []\n",
    "    stdev_stats = []\n",
    "    min_stats = []\n",
    "    max_stats = []\n",
    "    count_stats = []\n",
    "    \n",
    "    for i in np.unique(zone_raster):\n",
    "        zone = np.where(zone_raster == i, i, np.nan)\n",
    "        mean_stats.append(np.nanmean(zone * value_raster))\n",
    "        stdev_stats.append(np.nanstd(zone * value_raster))\n",
    "        min_stats.append(np.nanmin(zone * value_raster))\n",
    "        max_stats.append(np.nanmax(zone * value_raster))\n",
    "        count_stats.append(np.where(zone_raster == i, 1, 0 ).sum())\n",
    "\n",
    "    zonal_stats = {'Mean': mean_stats, 'Std. Dev.': stdev_stats, 'Min': min_stats, 'Max': max_stats, 'Count': count_stats}\n",
    "    df=pd.DataFrame(zonal_stats)\n",
    "    df.to_csv(output_csv)\n",
    "    return df\n",
    "\n",
    "zonal_satistics_as_table(slope_reclass, mean_coeficient, 'slope.csv')\n",
    "zonal_satistics_as_table(aspect_reclass, mean_coeficient, 'aspect.csv')   \n",
    "\n",
    "with rasterio.open(r'./data/data/bigElk_dem.tif') as dataset:\n",
    "    with rasterio.open('./data/data/mean_coeficient.tif' , 'w',\n",
    "                          driver='GTiff',\n",
    "                          height=mean_coeficient.shape[0],\n",
    "                          width=mean_coeficient.shape[1],\n",
    "                          count=1,\n",
    "                          dtype=mean_coeficient.dtype,\n",
    "                          crs=dataset.crs,\n",
    "                            transform=dataset.transform,\n",
    "                          nodta=dataset.nodata\n",
    "                          ) as out_dataset:\n",
    "        out_dataset.write(mean_coeficient,1)\n",
    "print('As the slope increases the number of burned pixels increases. The aspect did not seem to be as much of a factor, however there is more of a burned area in the East.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_satistics_as_table(slope_reclass, mean_coeficient, 'slope.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_satistics_as_table(aspect_reclass, mean_coeficient, 'aspect.csv')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(r'./data/data/bigElk_dem.tif') as dataset:\n",
    "    with rasterio.open('./data/data/mean_coeficient.tif' , 'w',\n",
    "                          driver='GTiff',\n",
    "                          height=mean_coeficient.shape[0],\n",
    "                          width=mean_coeficient.shape[1],\n",
    "                          count=1,\n",
    "                          dtype=mean_coeficient.dtype,\n",
    "                          crs=dataset.crs,\n",
    "                            transform=dataset.transform,\n",
    "                          nodta=dataset.nodata\n",
    "                          ) as out_dataset:\n",
    "        out_dataset.write(mean_coeficient,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
